import ast
import os
import re
import json
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

class QAReviewerAgent:
    def __init__(self, api_key: str = None):
        """
        Initializes the QA Reviewer Agent with DeepSeek Reasoner.
        Role: Strict Code Quality Gate.
        """
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        if not self.api_key:
            raise ValueError("DeepSeek API Key is required.")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
        self.model_name = "deepseek-reasoner"

    def review_code(self, code: str, strategy: Dict[str, Any], business_objective: str) -> Dict[str, Any]:
        """
        Conducts a strict Quality Assurance audit on the generated code.
        Focus: Mapping integrity, Leakage prevention, Safety, consistency.
        """
        static_reject = run_static_qa_checks(code)
        if static_reject:
            return static_reject
        
        output_format_instructions = """
        Return a raw JSON object:
        {
            "status": "APPROVED" | "APPROVE_WITH_WARNINGS" | "REJECTED",
            "feedback": "Detailed explanation of rejection reasons or 'QA Passed'.",
            "failed_gates": ["List", "of", "failed", "gates"],
            "required_fixes": ["List", "of", "required", "actions"]
        }
        """

        from src.utils.prompting import render_prompt

        SYSTEM_PROMPT_TEMPLATE = """
        You are the Lead QA Engineer.
        Your role is to strictly AUDIT python code generated by a junior Data Scientist.
        You must REJECT the code if it fails any of the Critical Quality Gates.
        
        CRITICAL QUALITY GATES:
        
        1. MAPPING SUMMARY (Mandatory):
           - The code MUST print a "Mapping Summary" or similar dict showing which features map to which columns.
           - Example: print(f"Mapping: Target={{target_col}}, Features={{features}}")
           
        2. CONSISTENCY CHECKS (Mandatory):
           - Check for column aliasing (two features mapping to same column).
           - Check for empty DataFrame.
           - Check target variation (nunique > 1).
           
        3. DATA LEAKAGE PREVENTION (Mandatory):
           - Target column must NOT be in X (features).
           - High cardinality columns (IDs) must be excluded unless justified.
           - If X is explicitly built from contract feature_cols and excludes extra columns, this is sufficient.
           
        4. OUTPUT SAFETY (Mandatory):
           - If saving plots, `os.makedirs('static/plots', exist_ok=True)` MUST be called.
           
        INPUT CONTEXT:
        - Business Objective: "$business_objective"
        - Strategy: $strategy_title
        
        INSTRUCTIONS:
        - Analyze the code line-by-line.
        - If any CRITICAL Gate is violated, INVALIDATE with status "REJECTED".
        - If issues are minor (Style, Comments, non-critical Best Practices) but code is SAFE and CORRECT, return "APPROVE_WITH_WARNINGS".
        - Provide specific, actionable feedback on what is missing and how to fix it.
        - Do not request stylistic changes. Focus on correctness and safety.
        
        OUTPUT FORMAT (JSON):
        $output_format_instructions
        """
        
        system_prompt = render_prompt(
            SYSTEM_PROMPT_TEMPLATE,
            business_objective=business_objective,
            strategy_title=strategy.get('title', 'Unknown'),
            output_format_instructions=output_format_instructions
        )

        USER_MESSAGE_TEMPLATE = """
        AUDIT THIS CODE:
        
        ```python
        $code
        ```
        """
        
        user_message = render_prompt(USER_MESSAGE_TEMPLATE, code=code)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            
            # Parse JSON
            try:
                result = json.loads(content)
                # Fallback normalization
                if result['status'] not in ['APPROVED', 'APPROVE_WITH_WARNINGS', 'REJECTED']:
                    result['status'] = 'REJECTED'
                    result['feedback'] = "QA Error: Invalid status returned."
                
                # Normalize lists
                for field in ['failed_gates', 'required_fixes']:
                    val = result.get(field, [])
                    if isinstance(val, str):
                        result[field] = [val]
                    elif not isinstance(val, list):
                        result[field] = []
                    else:
                         result[field] = val
                         
                return result
            except json.JSONDecodeError:
                return {
                    "status": "REJECTED", 
                    "feedback": "QA Error: Failed to parse JSON response.",
                    "failed_gates": ["JSON_PARSE_ERROR"],
                    "required_fixes": ["Fix JSON format"]
                }
                
        except Exception as e:
            return {
                "status": "REJECTED",
                "feedback": f"QA System Error: {e}"
            }


def _is_random_call(call_node: ast.Call) -> bool:
    """
    Detects calls that rely on random generators (numpy.random, random.*, default_rng, etc.).
    """
    try:
        func_repr = ast.unparse(call_node.func)
    except Exception:
        func_repr = ""
    func_lower = func_repr.lower()
    random_tokens = ["np.random", "numpy.random", "random.", "random("]
    random_funcs = ["normal", "uniform", "randint", "randn", "rand", "default_rng"]
    if any(tok in func_lower for tok in random_tokens):
        return True
    return any(func in func_lower for func in random_funcs)


def _call_name(call_node: ast.Call) -> str:
    try:
        return ast.unparse(call_node.func)
    except Exception:
        if isinstance(call_node.func, ast.Name):
            return call_node.func.id
        if isinstance(call_node.func, ast.Attribute):
            return call_node.func.attr
    return ""


_REGRESSOR_KEYWORDS = {
    "LinearRegression",
    "ElasticNet",
    "Lasso",
    "Ridge",
    "HuberRegressor",
    "SVR",
    "KNeighborsRegressor",
    "DecisionTreeRegressor",
    "RandomForestRegressor",
    "GradientBoostingRegressor",
    "XGBRegressor",
    "CatBoostRegressor",
    "ExtraTreesRegressor",
    "LGBMRegressor",
    "SGDRegressor",
    "LinearSVR",
}


def _looks_like_regressor(name: str) -> bool:
    if not name:
        return False
    if name.endswith("Regressor"):
        return True
    simple = name.split(".")[-1]
    return simple in _REGRESSOR_KEYWORDS or simple.lower() in {"svr"}


def _extract_target_name(target_node: ast.AST) -> Optional[str]:
    if isinstance(target_node, ast.Name):
        return target_node.id
    if isinstance(target_node, ast.Attribute):
        return target_node.attr
    if isinstance(target_node, ast.Subscript):
        try:
            return ast.unparse(target_node)
        except Exception:
            return None
    return None


def _expr_has_random_call(node: ast.AST) -> bool:
    class _RandomVisitor(ast.NodeVisitor):
        def __init__(self):
            self.found = False

        def visit_Call(self, call):
            if _is_random_call(call):
                self.found = True
            self.generic_visit(call)

    visitor = _RandomVisitor()
    visitor.visit(node)
    return visitor.found


def _is_split_fabrication_call(call_node: ast.Call) -> bool:
    if not isinstance(call_node.func, ast.Attribute):
        return False
    if call_node.func.attr != "split":
        return False
    # Detect patterns like df["col"].str.split(..., expand=True)
    base = call_node.func.value
    is_str_access = isinstance(base, ast.Attribute) and base.attr == "str"
    has_expand_true = any(
        isinstance(kw, ast.keyword) and kw.arg == "expand" and isinstance(kw.value, ast.Constant) and bool(kw.value.value) is True
        for kw in call_node.keywords
    )
    if is_str_access and has_expand_true:
        return True
    try:
        func_repr = ast.unparse(call_node.func).lower()
    except Exception:
        func_repr = ""
    return ".str.split" in func_repr and "expand=true" in func_repr


def _expr_has_split_fabrication(node: ast.AST) -> bool:
    class _SplitVisitor(ast.NodeVisitor):
        def __init__(self):
            self.found = False

        def visit_Call(self, call):
            if _is_split_fabrication_call(call):
                self.found = True
            self.generic_visit(call)

    visitor = _SplitVisitor()
    visitor.visit(node)
    return visitor.found


def _condition_checks_nunique_le_one(test_node: ast.AST) -> bool:
    if not isinstance(test_node, ast.Compare):
        return False
    left = test_node.left
    if not isinstance(left, ast.Call):
        return False
    func = left.func
    if not (isinstance(func, ast.Attribute) and func.attr == "nunique"):
        return False
    valid_op = any(isinstance(op, (ast.LtE, ast.Lt, ast.Eq)) for op in test_node.ops)
    comparator_consts = [
        comp
        for comp in test_node.comparators
        if isinstance(comp, ast.Constant) and isinstance(comp.value, (int, float))
    ]
    if not comparator_consts:
        return False
    for op, comp in zip(test_node.ops, comparator_consts):
        if isinstance(op, ast.Eq) and comp.value == 1:
            return True
        if isinstance(op, ast.LtE) and comp.value <= 1:
            return True
        if isinstance(op, ast.Lt) and comp.value <= 2:
            return True
    # Fallback: accept any <=1 threshold
    threshold_match = any(const.value <= 1 for const in comparator_consts)
    return valid_op and threshold_match


def _if_has_value_error_raise(body_nodes) -> bool:
    for node in body_nodes:
        if isinstance(node, ast.Raise):
            exc = node.exc
            if isinstance(exc, ast.Call) and isinstance(exc.func, ast.Name) and exc.func.id == "ValueError":
                return True
        for child in ast.walk(node):
            if isinstance(child, ast.Raise):
                exc = child.exc
                if isinstance(exc, ast.Call) and isinstance(exc.func, ast.Name) and exc.func.id == "ValueError":
                    return True
    return False


class _StaticQAScanner(ast.NodeVisitor):
    def __init__(self):
        self.has_random_target_noise = False
        self.has_split_fabrication = False
        self.has_variance_guard = False
        self.has_leakage_assert = False
        self.has_regression_model = False
        self.has_regression_metric = False
        self.has_fit_call = False
        self.has_infer_group_key_call = False
        self.has_group_split_usage = False

    def visit_Assign(self, node: ast.Assign):
        self._handle_assignment(node.targets, node.value)
        self.generic_visit(node)

    def visit_AnnAssign(self, node: ast.AnnAssign):
        targets = [node.target]
        self._handle_assignment(targets, node.value)
        self.generic_visit(node)

    def visit_AugAssign(self, node: ast.AugAssign):
        targets = [node.target]
        self._handle_assignment(targets, node.value)
        self.generic_visit(node)

    def visit_Call(self, node: ast.Call):
        if _is_split_fabrication_call(node):
            self.has_split_fabrication = True
        name = _call_name(node)
        if "assert_no_deterministic_target_leakage" in name:
            self.has_leakage_assert = True
        if _looks_like_regressor(name):
            self.has_regression_model = True
        metric_names = {"r2_score", "mean_squared_error", "mean_absolute_error", "mean_absolute_percentage_error"}
        simple_name = name.split(".")[-1]
        if simple_name in metric_names:
            self.has_regression_metric = True
        if simple_name == "fit":
            self.has_fit_call = True
        if "infer_group_key" in name.lower():
            self.has_infer_group_key_call = True
        if simple_name == "split":
            if len(node.args) >= 3 or any(isinstance(kw, ast.keyword) and kw.arg == "groups" for kw in node.keywords):
                self.has_group_split_usage = True
        if any(isinstance(kw, ast.keyword) and kw.arg == "groups" for kw in node.keywords):
            self.has_group_split_usage = True
        self.generic_visit(node)

    def visit_If(self, node: ast.If):
        if _condition_checks_nunique_le_one(node.test) and _if_has_value_error_raise(node.body):
            self.has_variance_guard = True
        self.generic_visit(node)

    def _handle_assignment(self, targets, value):
        if value is None:
            return
        if _expr_has_random_call(value):
            for tgt in targets:
                name = _extract_target_name(tgt)
                if not name:
                    continue
                name_lower = name.lower()
                if name_lower == "y" or "target" in name_lower:
                    self.has_random_target_noise = True
        if _expr_has_split_fabrication(value):
            self.has_split_fabrication = True


def run_static_qa_checks(code: str) -> Optional[Dict[str, Any]]:
    """
    Deterministic pre-checks to block unsafe patterns without relying on the LLM.
    """
    def _detect_perfect_score_pattern(text: str) -> bool:
        lowered = text.lower()
        patterns = [
            r"r2[^\\n]{0,50}(1\\.0|0\\.99|0\\.98)",
            r"r[\s_]?2[\s:=><]{1,3}(1\\.0|0\\.99|0\\.98)",
            r"mae[^\\n]{0,40}(0\\.0+|1e-0*[1-6])",
        ]
        import re

        for pat in patterns:
            if re.search(pat, lowered, flags=re.IGNORECASE):
                return True
        return False

    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None

    scanner = _StaticQAScanner()
    scanner.visit(tree)

    if scanner.has_random_target_noise:
        return {
            "status": "REJECTED",
            "feedback": "No synthetic target noise allowed: target modifications driven by random generators detected.",
            "failed_gates": ["TARGET_NOISE"],
            "required_fixes": ["Remove random/jitter modifications to the target and enforce variance check instead."]
        }

    if scanner.has_split_fabrication:
        return {
            "status": "REJECTED",
            "feedback": "Delimiter mismatch must be fixed via dialect; do not fabricate columns via split/expand.",
            "failed_gates": ["DIALECT_MISMATCH_HANDLING"],
            "required_fixes": ["Load with correct output_dialect and abort on delimiter mismatch; do not split columns."]
        }

    if not scanner.has_variance_guard:
        return {
            "status": "REJECTED",
            "feedback": "Missing target variance guard (nunique <= 1 must raise ValueError).",
            "failed_gates": ["TARGET_VARIANCE"],
            "required_fixes": ["Add an explicit nunique<=1 check that raises ValueError before training."]
        }

    regression_present = scanner.has_regression_model or (scanner.has_fit_call and scanner.has_regression_metric)

    if regression_present and not scanner.has_leakage_assert:
        return {
            "status": "REJECTED",
            "feedback": "Regression detected but assert_no_deterministic_target_leakage is missing before training.",
            "failed_gates": ["LEAKAGE_GUARD"],
            "required_fixes": ["Call assert_no_deterministic_target_leakage(...) on regression tasks before fitting."]
        }

    if scanner.has_infer_group_key_call and not scanner.has_group_split_usage:
        return {
            "status": "REJECTED",
            "feedback": "Group key inferred but group-aware split not used. Apply GroupKFold/GroupShuffleSplit with the inferred groups.",
            "failed_gates": ["GROUP_SPLIT_MISSING"],
            "required_fixes": ["Use GroupKFold/GroupShuffleSplit (or groups=) when infer_group_key returns a grouping vector."]
        }

    if _detect_perfect_score_pattern(code) and not (scanner.has_leakage_assert or "leakage" in code.lower()):
        return {
            "status": "REJECTED",
            "feedback": "Perfect/near-perfect score pattern detected; require explicit deterministic leakage audit and explanation.",
            "failed_gates": ["PERFECT_SCORE_JUSTIFICATION"],
            "required_fixes": ["Explain high R2/low MAE and include assert_no_deterministic_target_leakage before training."]
        }

    return None


def collect_static_qa_facts(code: str) -> Dict[str, bool]:
    facts = {"variance_guard": False}
    try:
        tree = ast.parse(code)
    except Exception:
        return facts
    scanner = _StaticQAScanner()
    scanner.visit(tree)
    facts["variance_guard"] = scanner.has_variance_guard
    return facts
