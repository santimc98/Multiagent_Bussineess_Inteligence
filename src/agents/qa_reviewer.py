import ast
import os
import re
import json
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

def _extract_json_object(text: str) -> Optional[str]:
    if not text:
        return None
    start = None
    depth = 0
    in_str = False
    escape = False
    for i, ch in enumerate(text):
        if start is None:
            if ch == "{":
                start = i
                depth = 1
                in_str = False
                escape = False
            continue
        if in_str:
            if escape:
                escape = False
            elif ch == "\\":
                escape = True
            elif ch == "\"":
                in_str = False
            continue
        if ch == "\"":
            in_str = True
        elif ch == "{":
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                return text[start:i + 1]
    return None

class QAReviewerAgent:
    def __init__(self, api_key: str = None):
        """
        Initializes the QA Reviewer Agent with MIMO v2 Flash.
        Role: Strict Code Quality Gate.
        """
        self.api_key = api_key or os.getenv("MIMO_API_KEY")
        if not self.api_key:
            raise ValueError("MIMO API Key is required.")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.xiaomimimo.com/v1"
        )
        self.model_name = "mimo-v2-flash"
        self.last_prompt = None
        self.last_response = None

    def review_code(
        self,
        code: str,
        strategy: Dict[str, Any],
        business_objective: str,
        evaluation_spec: Dict[str, Any] | None = None,
    ) -> Dict[str, Any]:
        """
        Conducts a strict Quality Assurance audit on the generated code.
        Focus: Mapping integrity, Leakage prevention, Safety, consistency.
        """
        static_facts = collect_static_qa_facts(code)
        static_result = run_static_qa_checks(code, evaluation_spec, static_facts)
        try:
            os.makedirs("data", exist_ok=True)
            facts_payload = static_result.get("facts") if isinstance(static_result, dict) else static_facts
            with open("data/qa_static_facts.json", "w", encoding="utf-8") as f:
                json.dump(facts_payload, f, indent=2)
        except Exception:
            pass
        if static_result and static_result.get("status") == "REJECTED":
            return static_result

        output_format_instructions = """
        Return a raw JSON object:
        {
            "status": "APPROVED" | "APPROVE_WITH_WARNINGS" | "REJECTED",
            "feedback": "Detailed explanation of rejection reasons or 'QA Passed'.",
            "failed_gates": ["List", "of", "failed", "gates"],
            "required_fixes": ["List", "of", "required", "actions"]
        }
        """

        from src.utils.prompting import render_prompt

        eval_spec_json = json.dumps(evaluation_spec or {}, indent=2)
        qa_gates, default_gates = resolve_qa_gates(evaluation_spec)

        SYSTEM_PROMPT_TEMPLATE = """
        You are the Lead QA Engineer.
        Your role is to strictly AUDIT python code generated by a junior Data Scientist.
        You must REJECT the code if it fails any of the Critical Quality Gates.
        
        QUALITY GATES (SPEC-DRIVEN):
        
        1. MAPPING SUMMARY (only if gate enabled):
           - The code MUST print a "Mapping Summary" or similar dict showing which features map to which columns.
           - Example: print(f"Mapping: Target={{target_col}}, Features={{features}}")
           
        2. CONSISTENCY CHECKS (only if gate enabled):
           - Check for column aliasing (two features mapping to same column).
           - Check for empty DataFrame.
           - Check target variation (nunique > 1).
           
        3. DATA LEAKAGE PREVENTION (only if gate enabled):
           - Target column must NOT be in X (features).
           - High cardinality columns (IDs) must be excluded unless justified.
           - If X is explicitly built from contract feature_cols and excludes extra columns, this is sufficient.
           
        4. OUTPUT SAFETY (only if gate enabled):
           - If saving plots, `os.makedirs('static/plots', exist_ok=True)` MUST be called.

        5. INPUT CSV LOADING (only if gate enabled):
           - The code MUST call pandas.read_csv(...) to load the ML dataset specified in context (ml_data_path).

        6. NO SYNTHETIC DATA (only if gate enabled):
           - The code MUST NOT fabricate datasets via random generators, sklearn.datasets.make_*, or literal DataFrame constructors.

        7. CONTRACT COLUMNS (only if gate enabled):
           - The code MUST reference canonical contract columns explicitly.
           
        INPUT CONTEXT:
        - Business Objective: "$business_objective"
        - Strategy: $strategy_title
        - Evaluation Spec (JSON): $evaluation_spec_json
        - ML Dataset Path: $ml_data_path
        - QA Gates (only these can fail): $qa_gates
        - If QA Gates are empty, enforce minimal universal gates only (variance, train/eval separation, leakage basic, dialect mismatch handling, group split, security sandbox).
        
        INSTRUCTIONS:
        - Analyze the code line-by-line.
        - If any CRITICAL Gate is violated, INVALIDATE with status "REJECTED".
        - If issues are minor (Style, Comments, non-critical Best Practices) but code is SAFE and CORRECT, return "APPROVE_WITH_WARNINGS".
        - Provide specific, actionable feedback on what is missing and how to fix it.
        - Do not request stylistic changes. Focus on correctness and safety.
        - Only fail gates listed in QA Gates; otherwise mention as warnings.
        
        OUTPUT FORMAT (JSON):
        $output_format_instructions
        """
        
        ml_data_path = (evaluation_spec or {}).get("ml_data_path") or "data/cleaned_data.csv"
        system_prompt = render_prompt(
            SYSTEM_PROMPT_TEMPLATE,
            business_objective=business_objective,
            strategy_title=strategy.get('title', 'Unknown'),
            evaluation_spec_json=eval_spec_json,
            ml_data_path=ml_data_path,
            qa_gates=qa_gates,
            output_format_instructions=output_format_instructions
        )

        USER_MESSAGE_TEMPLATE = """
        AUDIT THIS CODE:
        
        ```python
        $code
        ```
        """
        
        user_message = render_prompt(USER_MESSAGE_TEMPLATE, code=code)
        self.last_prompt = system_prompt + "\n\n" + user_message
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            self.last_response = content
            
            # Parse JSON (tolerant)
            parse_error = None
            result = None
            try:
                result = json.loads(content)
            except json.JSONDecodeError as err:
                parse_error = err
                candidate = _extract_json_object(content)
                if candidate:
                    try:
                        result = json.loads(candidate)
                        parse_error = None
                    except json.JSONDecodeError as err2:
                        parse_error = err2

            if result is None:
                err_msg = f"QA JSON parse failed: {parse_error}"
                print(f"{err_msg}. Raw response: {content}")
                fallback = {
                    "status": "APPROVE_WITH_WARNINGS",
                    "feedback": f"QA Error: Failed to parse JSON response; defaulting to warnings. {parse_error}",
                    "failed_gates": [],
                    "required_fixes": [],
                }
                warnings = static_result.get("warnings", []) if static_result else []
                if warnings:
                    warning_text = "\n".join([f"- {w}" for w in warnings])
                    feedback = fallback.get("feedback") or "QA Passed with warnings."
                    fallback["feedback"] = f"{feedback}\nStatic QA warnings:\n{warning_text}"
                return fallback

            # Fallback normalization
            if result['status'] not in ['APPROVED', 'APPROVE_WITH_WARNINGS', 'REJECTED']:
                result['status'] = 'APPROVE_WITH_WARNINGS'
                result['feedback'] = "QA Error: Invalid status returned; downgraded to warnings."
            
            # Normalize lists
            for field in ['failed_gates', 'required_fixes']:
                val = result.get(field, [])
                if isinstance(val, str):
                    result[field] = [val]
                elif not isinstance(val, list):
                    result[field] = []
                else:
                     result[field] = val

            allowed = {str(g).lower() for g in (qa_gates or [])}
            if allowed:
                filtered = []
                for g in result.get("failed_gates", []):
                    if str(g).lower() in allowed:
                        filtered.append(g)
                result["failed_gates"] = filtered
                if result.get("status") == "REJECTED" and not result["failed_gates"]:
                    result["status"] = "APPROVE_WITH_WARNINGS"
                    result["feedback"] = "Spec-driven gating: no QA gates failed; downgraded to warnings."

            warnings = static_result.get("warnings", []) if static_result else []
            if warnings:
                if result.get("status") == "APPROVED":
                    result["status"] = "APPROVE_WITH_WARNINGS"
                feedback = result.get("feedback") or "QA Passed with warnings."
                warning_text = "\n".join([f"- {w}" for w in warnings])
                result["feedback"] = f"{feedback}\nStatic QA warnings:\n{warning_text}"
            return result
                
        except Exception as e:
            fallback = {
                "status": "APPROVE_WITH_WARNINGS",
                "feedback": f"QA System Error: {e}. Defaulting to warnings.",
                "failed_gates": [],
                "required_fixes": [],
            }
            warnings = static_result.get("warnings", []) if static_result else []
            if warnings:
                warning_text = "\n".join([f"- {w}" for w in warnings])
                fallback["feedback"] = f"{fallback.get('feedback')}\nStatic QA warnings:\n{warning_text}"
            return fallback


def _is_random_call(call_node: ast.Call) -> bool:
    """
    Detects calls that rely on random generators (numpy.random, random.*, default_rng, etc.).
    """
    try:
        func_repr = ast.unparse(call_node.func)
    except Exception:
        func_repr = ""
    func_lower = func_repr.lower()
    random_tokens = ["np.random", "numpy.random", "random.", "random("]
    random_funcs = ["normal", "uniform", "randint", "randn", "rand", "default_rng"]
    if any(tok in func_lower for tok in random_tokens):
        return True
    return any(func in func_lower for func in random_funcs)


def _is_sklearn_make_call(call_node: ast.Call) -> bool:
    name = _call_name(call_node)
    name_lower = name.lower()
    if "sklearn.datasets.make_" in name_lower or ".datasets.make_" in name_lower:
        return True
    if name_lower.startswith("make_"):
        return True
    return False


def _is_pure_literal_node(node: ast.AST) -> bool:
    if isinstance(node, ast.Constant):
        return True
    if isinstance(node, (ast.List, ast.Tuple, ast.Set)):
        return all(_is_pure_literal_node(elt) for elt in node.elts)
    if isinstance(node, ast.Dict):
        keys = [k for k in node.keys if k is not None]
        return all(_is_pure_literal_node(k) for k in keys) and all(
            _is_pure_literal_node(v) for v in node.values
        )
    return False


def _is_dataframe_literal_call(call_node: ast.Call) -> bool:
    name = _call_name(call_node)
    name_lower = name.lower()
    if not name_lower.endswith("dataframe"):
        return False
    for arg in call_node.args[:1]:
        if _is_pure_literal_node(arg):
            return True
    for kw in call_node.keywords:
        if kw.arg in (None, "data") and _is_pure_literal_node(kw.value):
            return True
    return False


def _is_synthetic_data_call(call_node: ast.Call) -> bool:
    return _is_random_call(call_node) or _is_sklearn_make_call(call_node) or _is_dataframe_literal_call(call_node)


def _call_name(call_node: ast.Call) -> str:
    try:
        return ast.unparse(call_node.func)
    except Exception:
        if isinstance(call_node.func, ast.Name):
            return call_node.func.id
        if isinstance(call_node.func, ast.Attribute):
            return call_node.func.attr
    return ""


def _node_mentions_mapping(node: ast.AST) -> bool:
    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return "mapping" in node.value.lower()
    if isinstance(node, ast.Name):
        return "mapping" in node.id.lower()
    if isinstance(node, ast.Attribute):
        return "mapping" in node.attr.lower()
    if isinstance(node, ast.JoinedStr):
        for value in node.values:
            if isinstance(value, ast.Constant) and isinstance(value.value, str):
                if "mapping" in value.value.lower():
                    return True
    return False


_REGRESSOR_KEYWORDS = {
    "LinearRegression",
    "ElasticNet",
    "Lasso",
    "Ridge",
    "HuberRegressor",
    "SVR",
    "KNeighborsRegressor",
    "DecisionTreeRegressor",
    "RandomForestRegressor",
    "GradientBoostingRegressor",
    "XGBRegressor",
    "CatBoostRegressor",
    "ExtraTreesRegressor",
    "LGBMRegressor",
    "SGDRegressor",
    "LinearSVR",
}


def _looks_like_regressor(name: str) -> bool:
    if not name:
        return False
    if name.endswith("Regressor"):
        return True
    simple = name.split(".")[-1]
    return simple in _REGRESSOR_KEYWORDS or simple.lower() in {"svr"}


def _extract_target_name(target_node: ast.AST) -> Optional[str]:
    if isinstance(target_node, ast.Name):
        return target_node.id
    if isinstance(target_node, ast.Attribute):
        return target_node.attr
    if isinstance(target_node, ast.Subscript):
        try:
            return ast.unparse(target_node)
        except Exception:
            return None
    return None


def _expr_has_random_call(node: ast.AST) -> bool:
    class _RandomVisitor(ast.NodeVisitor):
        def __init__(self):
            self.found = False

        def visit_Call(self, call):
            if _is_random_call(call):
                self.found = True
            self.generic_visit(call)

    visitor = _RandomVisitor()
    visitor.visit(node)
    return visitor.found


def _is_split_fabrication_call(call_node: ast.Call) -> bool:
    if not isinstance(call_node.func, ast.Attribute):
        return False
    if call_node.func.attr != "split":
        return False
    # Detect patterns like df["col"].str.split(..., expand=True)
    base = call_node.func.value
    is_str_access = isinstance(base, ast.Attribute) and base.attr == "str"
    has_expand_true = any(
        isinstance(kw, ast.keyword) and kw.arg == "expand" and isinstance(kw.value, ast.Constant) and bool(kw.value.value) is True
        for kw in call_node.keywords
    )
    if is_str_access and has_expand_true:
        return True
    try:
        func_repr = ast.unparse(call_node.func).lower()
    except Exception:
        func_repr = ""
    return ".str.split" in func_repr and "expand=true" in func_repr


def _expr_has_split_fabrication(node: ast.AST) -> bool:
    class _SplitVisitor(ast.NodeVisitor):
        def __init__(self):
            self.found = False

        def visit_Call(self, call):
            if _is_split_fabrication_call(call):
                self.found = True
            self.generic_visit(call)

    visitor = _SplitVisitor()
    visitor.visit(node)
    return visitor.found


def _condition_checks_nunique_le_one(test_node: ast.AST) -> bool:
    if not isinstance(test_node, ast.Compare):
        return False
    left = test_node.left
    if not isinstance(left, ast.Call):
        return False
    func = left.func
    if not (isinstance(func, ast.Attribute) and func.attr == "nunique"):
        return False
    valid_op = any(isinstance(op, (ast.LtE, ast.Lt, ast.Eq)) for op in test_node.ops)
    comparator_consts = [
        comp
        for comp in test_node.comparators
        if isinstance(comp, ast.Constant) and isinstance(comp.value, (int, float))
    ]
    if not comparator_consts:
        return False
    for op, comp in zip(test_node.ops, comparator_consts):
        if isinstance(op, ast.Eq) and comp.value == 1:
            return True
        if isinstance(op, ast.LtE) and comp.value <= 1:
            return True
        if isinstance(op, ast.Lt) and comp.value <= 2:
            return True
    # Fallback: accept any <=1 threshold
    threshold_match = any(const.value <= 1 for const in comparator_consts)
    return valid_op and threshold_match


def _if_has_value_error_raise(body_nodes) -> bool:
    for node in body_nodes:
        if isinstance(node, ast.Raise):
            exc = node.exc
            if isinstance(exc, ast.Call) and isinstance(exc.func, ast.Name) and exc.func.id == "ValueError":
                return True
        for child in ast.walk(node):
            if isinstance(child, ast.Raise):
                exc = child.exc
                if isinstance(exc, ast.Call) and isinstance(exc.func, ast.Name) and exc.func.id == "ValueError":
                    return True
    return False


class _StaticQAScanner(ast.NodeVisitor):
    def __init__(self):
        self.has_random_target_noise = False
        self.has_split_fabrication = False
        self.has_variance_guard = False
        self.has_leakage_assert = False
        self.has_regression_model = False
        self.has_regression_metric = False
        self.has_fit_call = False
        self.has_infer_group_key_call = False
        self.has_group_split_usage = False
        self.has_security_violation = False
        self.has_train_eval_split = False
        self.has_mapping_summary_print = False
        self.has_mkdirs = False
        self.forbidden_imports_found = False
        self.has_read_csv = False
        self.has_synthetic_data = False

    def visit_Assign(self, node: ast.Assign):
        self._handle_assignment(node.targets, node.value)
        self.generic_visit(node)

    def visit_AnnAssign(self, node: ast.AnnAssign):
        targets = [node.target]
        self._handle_assignment(targets, node.value)
        self.generic_visit(node)

    def visit_AugAssign(self, node: ast.AugAssign):
        targets = [node.target]
        self._handle_assignment(targets, node.value)
        self.generic_visit(node)

    def visit_Call(self, node: ast.Call):
        if _is_split_fabrication_call(node):
            self.has_split_fabrication = True
        name = _call_name(node)
        if _is_synthetic_data_call(node):
            self.has_synthetic_data = True
        if isinstance(node.func, ast.Name) and node.func.id == "print":
            if any(_node_mentions_mapping(arg) for arg in node.args):
                self.has_mapping_summary_print = True
        if "read_csv" in name:
            self.has_read_csv = True
        if "assert_no_deterministic_target_leakage" in name:
            self.has_leakage_assert = True
        if _looks_like_regressor(name):
            self.has_regression_model = True
        metric_names = {"r2_score", "mean_squared_error", "mean_absolute_error", "mean_absolute_percentage_error"}
        simple_name = name.split(".")[-1]
        if simple_name in {
            "train_test_split",
            "cross_val_score",
            "cross_validate",
            "cross_val_predict",
            "KFold",
            "StratifiedKFold",
            "GroupKFold",
            "TimeSeriesSplit",
            "ShuffleSplit",
            "StratifiedShuffleSplit",
            "GroupShuffleSplit",
        } or "train_test_split" in name:
            self.has_train_eval_split = True
        if simple_name in metric_names:
            self.has_regression_metric = True
        if simple_name == "fit":
            self.has_fit_call = True
        if "infer_group_key" in name.lower():
            self.has_infer_group_key_call = True
        if simple_name == "split":
            if len(node.args) >= 3 or any(isinstance(kw, ast.keyword) and kw.arg == "groups" for kw in node.keywords):
                self.has_group_split_usage = True
        if any(isinstance(kw, ast.keyword) and kw.arg == "groups" for kw in node.keywords):
            self.has_group_split_usage = True
        forbidden_calls = {
            "os.system",
            "subprocess.run",
            "subprocess.Popen",
            "subprocess.call",
            "requests.get",
            "requests.post",
            "requests.put",
            "requests.delete",
        }
        if name in forbidden_calls:
            self.has_security_violation = True
        if name.endswith("makedirs") or name.endswith(".mkdir") or name == "mkdir":
            self.has_mkdirs = True
        self.generic_visit(node)

    def visit_Import(self, node: ast.Import):
        forbidden = {"sys", "subprocess", "requests", "socket"}
        for alias in node.names:
            if alias.name.split(".")[0] in forbidden:
                self.has_security_violation = True
                self.forbidden_imports_found = True
        self.generic_visit(node)

    def visit_ImportFrom(self, node: ast.ImportFrom):
        forbidden = {"sys", "subprocess", "requests", "socket"}
        if node.module and node.module.split(".")[0] in forbidden:
            self.has_security_violation = True
            self.forbidden_imports_found = True
        self.generic_visit(node)

    def visit_If(self, node: ast.If):
        if _condition_checks_nunique_le_one(node.test) and _if_has_value_error_raise(node.body):
            self.has_variance_guard = True
        self.generic_visit(node)

    def _handle_assignment(self, targets, value):
        if value is None:
            return
        if _expr_has_random_call(value):
            for tgt in targets:
                name = _extract_target_name(tgt)
                if not name:
                    continue
                name_lower = name.lower()
                if name_lower == "y" or "target" in name_lower:
                    self.has_random_target_noise = True
        if _expr_has_split_fabrication(value):
            self.has_split_fabrication = True


MANDATORY_QA_GATES = [
    "must_read_input_csv",
    "no_synthetic_data",
    "must_reference_contract_columns",
]

DEFAULT_QA_GATES = [
    "target_variance_guard",
    "train_eval_split",
    "leakage_prevention",
    "dialect_mismatch_handling",
    "group_split_required",
    "security_sandbox",
    *MANDATORY_QA_GATES,
]


def resolve_qa_gates(evaluation_spec: Dict[str, Any] | None) -> tuple[list[str], bool]:
    qa_gates = []
    if isinstance(evaluation_spec, dict):
        qa_gates = (
            evaluation_spec.get("qa_gates")
            or evaluation_spec.get("gates")
            or evaluation_spec.get("reviewer_gates")
            or []
        )
    if isinstance(qa_gates, list) and qa_gates:
        merged = list(dict.fromkeys([*qa_gates, *MANDATORY_QA_GATES]))
        return merged, False
    return list(DEFAULT_QA_GATES), True


def _resolve_contract_columns_for_qa(evaluation_spec: Dict[str, Any] | None) -> List[str]:
    columns: List[str] = []
    if isinstance(evaluation_spec, dict):
        for key in ("canonical_columns", "contract_columns", "required_columns", "allowed_columns"):
            vals = evaluation_spec.get(key)
            if isinstance(vals, list):
                columns.extend([str(c) for c in vals if c])
        data_reqs = evaluation_spec.get("data_requirements")
        if isinstance(data_reqs, list):
            for req in data_reqs:
                if not isinstance(req, dict):
                    continue
                name = req.get("canonical_name") or req.get("name")
                if name:
                    columns.append(str(name))
    if not columns:
        return []
    return columns


def _code_mentions_columns(code: str, columns: List[str], tree: ast.AST | None = None) -> bool:
    if not columns:
        return False
    col_set = {str(c) for c in columns if c}
    if tree is not None:
        literals = {
            node.value
            for node in ast.walk(tree)
            if isinstance(node, ast.Constant) and isinstance(node.value, str)
        }
        for col in col_set:
            if col in literals:
                return True
    lowered = code.lower()
    return any(col.lower() in lowered for col in col_set)


def run_static_qa_checks(
    code: str,
    evaluation_spec: Dict[str, Any] | None = None,
    facts: Dict[str, Any] | None = None,
) -> Optional[Dict[str, Any]]:
    """
    Deterministic pre-checks to block unsafe patterns without relying on the LLM.
    """
    def _detect_perfect_score_pattern(text: str) -> bool:
        lowered = text.lower()
        patterns = [
            r"r2[^\\n]{0,50}(1\\.0|0\\.99|0\\.98)",
            r"r[\s_]?2[\s:=><]{1,3}(1\\.0|0\\.99|0\\.98)",
            r"mae[^\\n]{0,40}(0\\.0+|1e-0*[1-6])",
        ]
        import re

        for pat in patterns:
            if re.search(pat, lowered, flags=re.IGNORECASE):
                return True
        return False

    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None

    scanner = _StaticQAScanner()
    scanner.visit(tree)
    qa_gates, default_used = resolve_qa_gates(evaluation_spec)
    qa_gate_set = set(qa_gates or [])
    require_variance_guard = "target_variance_guard" in qa_gate_set
    require_leakage_guard = "leakage_prevention" in qa_gate_set
    require_dialect_guard = "dialect_mismatch_handling" in qa_gate_set
    require_group_split = "group_split_required" in qa_gate_set
    require_security = "security_sandbox" in qa_gate_set
    require_read_csv = "must_read_input_csv" in qa_gate_set
    ml_data_path = (evaluation_spec or {}).get("ml_data_path") or "data/cleaned_data.csv"
    require_no_synth = "no_synthetic_data" in qa_gate_set
    require_contract_columns = "must_reference_contract_columns" in qa_gate_set
    train_eval_gate = None
    if "train_eval_split" in qa_gate_set:
        train_eval_gate = "train_eval_split"
    elif "train_eval_separation" in qa_gate_set:
        train_eval_gate = "train_eval_separation"
    require_train_eval = train_eval_gate is not None

    warnings: List[str] = []
    failed_gates: List[str] = []
    required_fixes: List[str] = []

    def _flag(gate: str, message: str, fix: str) -> None:
        if gate in qa_gate_set:
            failed_gates.append(gate)
            required_fixes.append(fix)
        else:
            warnings.append(message)

    if scanner.has_security_violation:
        _flag(
            "security_sandbox",
            "Security sandbox violation detected (forbidden import or call).",
            "Remove forbidden imports/calls (sys, subprocess, requests, os.system).",
        )

    if scanner.has_random_target_noise:
        _flag(
            "target_variance_guard",
            "Target modifications driven by random generators detected.",
            "Remove random/jitter modifications to the target and enforce variance check instead.",
        )

    if scanner.has_split_fabrication:
        _flag(
            "dialect_mismatch_handling",
            "Delimiter mismatch must be fixed via dialect; do not fabricate columns via split/expand.",
            "Load with correct output_dialect and abort on delimiter mismatch; do not split columns.",
        )

    if require_read_csv and not scanner.has_read_csv:
        _flag(
            "must_read_input_csv",
            f"Missing pandas.read_csv call; code must load the ML dataset ({ml_data_path}).",
            f"Read the ML dataset via pandas.read_csv('{ml_data_path}') and use it as the dataset source.",
        )

    if require_no_synth and scanner.has_synthetic_data:
        _flag(
            "no_synthetic_data",
            "Synthetic data construction detected (random generators, make_* datasets, or literal DataFrame).",
            "Remove synthetic data creation; load the real CSV and operate on contract columns only.",
        )

    contract_columns = _resolve_contract_columns_for_qa(evaluation_spec)
    if not contract_columns:
        require_contract_columns = False
    has_contract_column_reference = _code_mentions_columns(code, contract_columns, tree)
    if require_contract_columns and not has_contract_column_reference:
        _flag(
            "must_reference_contract_columns",
            "No references to contract canonical columns detected in code.",
            "Reference contract columns explicitly (canonical names) when selecting features/targets.",
        )

    if require_variance_guard and not scanner.has_variance_guard:
        _flag(
            "target_variance_guard",
            "Missing target variance guard (nunique <= 1 must raise ValueError).",
            "Add an explicit nunique<=1 check that raises ValueError before training.",
        )

    regression_present = scanner.has_regression_model or (scanner.has_fit_call and scanner.has_regression_metric)
    if require_leakage_guard and regression_present and not scanner.has_leakage_assert:
        _flag(
            "leakage_prevention",
            "Regression detected but assert_no_deterministic_target_leakage is missing before training.",
            "Call assert_no_deterministic_target_leakage(...) on regression tasks before fitting.",
        )

    if require_group_split and scanner.has_infer_group_key_call and not scanner.has_group_split_usage:
        _flag(
            "group_split_required",
            "Group key inferred but group-aware split not used.",
            "Use GroupKFold/GroupShuffleSplit (or groups=) when infer_group_key returns a grouping vector.",
        )

    if require_train_eval and scanner.has_fit_call and not scanner.has_train_eval_split:
        _flag(
            train_eval_gate,
            "Model training detected without explicit train/eval separation.",
            "Add train_test_split or a cross-validation strategy before fitting.",
        )

    if _detect_perfect_score_pattern(code) and not (scanner.has_leakage_assert or "leakage" in code.lower()):
        _flag(
            "leakage_prevention",
            "Perfect/near-perfect score pattern detected; require explicit leakage audit and explanation.",
            "Explain high R2/low MAE and include assert_no_deterministic_target_leakage before training.",
        )

    facts_payload = facts if isinstance(facts, dict) else collect_static_qa_facts(code)
    facts_payload["has_read_csv"] = scanner.has_read_csv
    facts_payload["has_synthetic_data"] = scanner.has_synthetic_data
    facts_payload["has_contract_column_reference"] = has_contract_column_reference
    facts_payload["contract_columns_checked"] = contract_columns
    facts_payload["qa_gates"] = qa_gates
    facts_payload["default_gates_used"] = default_used

    if failed_gates:
        return {
            "status": "REJECTED",
            "feedback": "Static QA gate failures detected.",
            "failed_gates": failed_gates,
            "required_fixes": required_fixes,
            "facts": facts_payload,
            "warnings": warnings,
        }
    if warnings:
        return {"status": "WARN", "warnings": warnings, "facts": facts_payload}
    return {"status": "PASS", "facts": facts_payload}


def collect_static_qa_facts(code: str) -> Dict[str, bool]:
    facts = {
        "has_variance_guard": False,
        "has_group_split_usage": False,
        "has_infer_group_key_call": False,
        "has_leakage_assert": False,
        "has_random_target_noise": False,
        "has_split_fabrication": False,
        "has_security_violation": False,
        "has_train_eval_split": False,
        "has_mapping_summary_print": False,
        "has_mkdirs": False,
        "forbidden_imports_found": False,
        "has_read_csv": False,
        "has_synthetic_data": False,
        "has_contract_column_reference": False,
    }
    try:
        tree = ast.parse(code)
    except Exception:
        return facts
    scanner = _StaticQAScanner()
    scanner.visit(tree)
    facts["has_variance_guard"] = scanner.has_variance_guard
    facts["has_group_split_usage"] = scanner.has_group_split_usage
    facts["has_infer_group_key_call"] = scanner.has_infer_group_key_call
    facts["has_leakage_assert"] = scanner.has_leakage_assert
    facts["has_random_target_noise"] = scanner.has_random_target_noise
    facts["has_split_fabrication"] = scanner.has_split_fabrication
    facts["has_security_violation"] = scanner.has_security_violation
    facts["has_train_eval_split"] = scanner.has_train_eval_split
    facts["has_mapping_summary_print"] = scanner.has_mapping_summary_print
    facts["has_mkdirs"] = scanner.has_mkdirs
    facts["forbidden_imports_found"] = scanner.forbidden_imports_found
    facts["has_read_csv"] = scanner.has_read_csv
    facts["has_synthetic_data"] = scanner.has_synthetic_data
    facts["has_contract_column_reference"] = _code_mentions_columns(
        code, _resolve_contract_columns_for_qa(None), tree
    )
    return facts
